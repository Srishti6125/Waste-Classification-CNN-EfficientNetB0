# ğŸ—‘ï¸ Garbage Classification using EfficientNet

*A deep learning project for classifying garbage images into **12 waste categories** using **EfficientNetB0** and transfer learning.*

---

## ğŸš€ Overview
- **Multi-class image classification**
- **EfficientNetB0 (ImageNet pretrained)**
- Focus on **high accuracy & strong generalization**
- **Best model selected based on test performance**

---

## ğŸ§  Classes (12)
`battery`, `biological`, `brown-glass`, `cardboard`, `clothes`,  
`green-glass`, `metal`, `paper`, `plastic`, `shoes`, `trash`, `white-glass`

---

## ğŸ“¦ Dataset
- **Source:** [Kaggle â€“ Garbage Classification Dataset](https://www.kaggle.com/datasets/mostafaabla/garbage-classification)
- Images organized in **class-wise folders**
- **Data Split:**  
  - ğŸŸ¢ Train â€” 80%  
  - ğŸŸ¡ Validation â€” 10%  
  - ğŸ”µ Test â€” 10%

---

## ğŸ—ï¸ Model Architecture
- **EfficientNetB0** backbone (`include_top=False`)
- **Global Average Pooling**
- **Dropout (0.3)** for regularization
- **Dense Softmax layer** (12 classes)

---

## ğŸ” Training Strategy

### ğŸ”¹ Stage 1 â€“ Transfer Learning
- Backbone **frozen**
- Trained **custom classification head**
- **Class weights** + **Early stopping**
- **Accuracy:** **95.66%**

### ğŸ”¹ Stage 2 â€“ Fine Tuning
- Unfroze **top convolution layers (last 40)**
- **Lower learning rate**
- **Accuracy:** **92.53%**

ğŸ“Œ **Final Model Chosen:**  
ğŸ‘‰ *Stage-1 model (better generalization on test data)*

---

## ğŸ“Š Results
- **Test Accuracy:** **â‰ˆ 95%+**
- Evaluation using:
  - Confusion Matrix  
  - Classification Report (Precision, Recall, F1-score)

---

## ğŸ’¾ Saved Artifacts
- `efficientnet_stage1_final.keras` â†’ **final trained model**
- `class_names.json` â†’ **class label mapping**

---

## ğŸ› ï¸ Tech Stack
**Python**, **TensorFlow/Keras**, **EfficientNetB0**,  
NumPy, Matplotlib, Scikit-learn

---

## ğŸ“Œ Note
This project prioritizes **model performance and robustness**.  
**Explainable AI (Grad-CAM)** is explored separately on a cleaner architecture.

---
